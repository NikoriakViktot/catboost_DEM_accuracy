{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-01T08:25:29.924950Z",
     "start_time": "2025-10-01T08:25:26.553760Z"
    }
   },
   "source": [
    "import duckdb, pandas as pd, numpy as np\n",
    "\n",
    "file_train_cls = 'data/NMAD_with_embeddings_cls.parquet'\n",
    "con = duckdb.connect(file_train_cls)\n",
    "\n",
    "# забираємо все потрібне під FABDEM\n",
    "df = con.execute(\"\"\"\n",
    "  SELECT\n",
    "    -- групування / просторові поля\n",
    "    rgt, track, spot, x_merc, y_merc,\n",
    "    -- таргет FABDEM\n",
    "    cls_nmad_fab, nmad_fab,\n",
    "    h_fab_dem, delta_fab_dem, abs_delta_fab_dem,\n",
    "    fab_dem_slope, fab_dem_twi, fab_dem_2000, fab_dem_stream,\n",
    "    x, y,\n",
    "    -- категоріальні LULC/geomorphon/landform\n",
    "    lulc_class, lulc_name, fab_dem_geomorphon, fab_dem_landform,\n",
    "    -- ембедінги (64 колонок або emb_all)\n",
    "    emb_001, emb_002, emb_003, emb_004, emb_005, emb_006, emb_007, emb_008,\n",
    "    emb_009, emb_010, emb_011, emb_012, emb_013, emb_014, emb_015, emb_016,\n",
    "    emb_017, emb_018, emb_019, emb_020, emb_021, emb_022, emb_023, emb_024,\n",
    "    emb_025, emb_026, emb_027, emb_028, emb_029, emb_030, emb_031, emb_032,\n",
    "    emb_033, emb_034, emb_035, emb_036, emb_037, emb_038, emb_039, emb_040,\n",
    "    emb_041, emb_042, emb_043, emb_044, emb_045, emb_046, emb_047, emb_048,\n",
    "    emb_049, emb_050, emb_051, emb_052, emb_053, emb_054, emb_055, emb_056,\n",
    "    emb_057, emb_058, emb_059, emb_060, emb_061, emb_062, emb_063, emb_064,\n",
    "    -- або emb_all якщо зберігав як масив/список\n",
    "  FROM NMAD_with_embeddings_cls\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "# Таргет\n",
    "df[\"cls_nmad_fab\"] = df[\"cls_nmad_fab\"].astype(int)\n",
    "\n",
    "# Група для spatial split\n",
    "df[\"group_id\"] = (df[\"rgt\"].astype(int).astype(str) + \"_\" +\n",
    "                  df[\"track\"].astype(int).astype(str))\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T08:25:41.863336Z",
     "start_time": "2025-10-01T08:25:41.402108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# рахуємо розмір груп\n",
    "gsize = df.groupby(\"group_id\").size().rename(\"grp_n\")  # <-- унікальна назва!\n",
    "\n",
    "# приєднуємо розмір груп до df (без конфлікту імен)\n",
    "df = df.join(gsize, on=\"group_id\")\n",
    "\n",
    "MIN_TEST_N = 3000\n",
    "df[\"is_big_group\"] = df[\"grp_n\"] >= MIN_TEST_N\n"
   ],
   "id": "2d88761d4066968a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T08:27:35.108173Z",
     "start_time": "2025-10-01T08:27:35.105693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_cols = [\n",
    "    \"x\", \"y\",\"h_fab_dem\",\"delta_fab_dem\",\"abs_delta_fab_dem\",\n",
    "    \"fab_dem_slope\",\"fab_dem_twi\",\"fab_dem_2000\",\"fab_dem_stream\",\n",
    "    \"x_merc\",\"y_merc\"\n",
    "]\n",
    "cat_cols = [\"lulc_class\",\"lulc_name\",\"fab_dem_geomorphon\",\"fab_dem_landform\"]\n",
    "\n",
    "# ембедінги (якщо є всі 64 канали окремими колонками)\n",
    "emb_cols = [f\"emb_{i:03d}\" for i in range(1,65) if f\"emb_{i:03d}\" in df.columns]\n"
   ],
   "id": "bff3d8dca8bce0cc",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T08:27:46.828391Z",
     "start_time": "2025-10-01T08:27:45.567820Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collapse_rare(df, col, min_frac=0.01):\n",
    "    vc = df[col].value_counts(normalize=True)\n",
    "    rare = vc[vc < min_frac].index\n",
    "    df[col] = df[col].where(~df[col].isin(rare), \"__OTHER__\")\n",
    "    return df\n",
    "\n",
    "for c in cat_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(str)\n",
    "        df = collapse_rare(df, c, 0.01)\n"
   ],
   "id": "614bebf6af7f6d07",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T08:28:06.352500Z",
     "start_time": "2025-10-01T08:28:00.074068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "\n",
    "y = df[\"cls_nmad_fab\"].astype(int)\n",
    "groups = df[\"group_id\"]\n",
    "is_big = df[\"is_big_group\"].values\n",
    "\n",
    "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "folds = []\n",
    "big_idx = np.where(is_big)[0]\n",
    "y_big   = y.iloc[big_idx]\n",
    "grp_big = groups.iloc[big_idx]\n",
    "\n",
    "for fold, (tr_big, te_big) in enumerate(sgkf.split(big_idx, y_big, groups=grp_big), 1):\n",
    "    tr_idx = big_idx[tr_big]\n",
    "    te_idx = big_idx[te_big]\n",
    "    # усі \"малі\" групи — тільки в train\n",
    "    tr_idx = np.concatenate([tr_idx, np.where(~is_big)[0]])\n",
    "    folds.append((np.sort(tr_idx), np.sort(te_idx)))\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold}: \"\n",
    "        f\"train groups = {df.iloc[tr_idx]['group_id'].nunique()} | \"\n",
    "        f\"test groups = {df.iloc[te_idx]['group_id'].nunique()}\"\n",
    "    )\n",
    "\n",
    "# Перевірки\n",
    "for k, (tr, te) in enumerate(folds, 1):\n",
    "    assert set(df.iloc[tr][\"group_id\"]).isdisjoint(set(df.iloc[te][\"group_id\"]))\n",
    "    print(f\"Fold {k} class dist train:\",\n",
    "          y.iloc[tr].value_counts(normalize=True).sort_index().round(3).to_dict(),\n",
    "          \"| test:\",\n",
    "          y.iloc[te].value_counts(normalize=True).sort_index().round(3).to_dict())\n"
   ],
   "id": "bbd5dca3d0d3d51c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train groups = 8 | test groups = 3\n",
      "Fold 2: train groups = 8 | test groups = 3\n",
      "Fold 3: train groups = 9 | test groups = 2\n",
      "Fold 4: train groups = 10 | test groups = 1\n",
      "Fold 5: train groups = 10 | test groups = 1\n",
      "Fold 1 class dist train: {0: 0.332, 1: 0.329, 2: 0.34} | test: {0: 0.326, 1: 0.332, 2: 0.342}\n",
      "Fold 2 class dist train: {0: 0.326, 1: 0.332, 2: 0.343} | test: {0: 0.338, 1: 0.326, 2: 0.337}\n",
      "Fold 3 class dist train: {0: 0.331, 1: 0.333, 2: 0.336} | test: {0: 0.319, 1: 0.308, 2: 0.372}\n",
      "Fold 4 class dist train: {0: 0.33, 1: 0.326, 2: 0.344} | test: {0: 0.328, 1: 0.359, 2: 0.313}\n",
      "Fold 5 class dist train: {0: 0.33, 1: 0.33, 2: 0.34} | test: {0: 0.33, 1: 0.327, 2: 0.343}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T08:34:36.937291Z",
     "start_time": "2025-10-01T08:31:57.134122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score, confusion_matrix, classification_report\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "\n",
    "# --- налаштування ---\n",
    "SAVE_DIR = \"artifacts_fabdem_cv\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "REDUCED_DIM = 32  # скільки компонент залишати з 64-ембедінгів\n",
    "\n",
    "# --- підготовка PCA об'єкта (фітитимемо на train усередині 1-го фолду) ---\n",
    "pca = PCA(n_components=REDUCED_DIM, random_state=42) if len(emb_cols) > 0 else None\n",
    "\n",
    "all_fold_metrics = []\n",
    "best_model = None\n",
    "best_macro_f1 = -1.0\n",
    "best_fold_id = None\n",
    "\n",
    "# для збереження усіх тестових прогнозів по фолдах\n",
    "test_preds_concat = []\n",
    "\n",
    "for k, (tr, te) in enumerate(folds, 1):\n",
    "    print(f\"\\n===== FOLD {k} =====\")\n",
    "    y_tr, y_te = y.iloc[tr], y.iloc[te]\n",
    "\n",
    "    # числові/категоріальні\n",
    "    Xn_tr = df.loc[tr, num_cols].copy()\n",
    "    Xn_te = df.loc[te, num_cols].copy()\n",
    "    Xc_tr = df.loc[tr, cat_cols].astype(str).copy()\n",
    "    Xc_te = df.loc[te, cat_cols].astype(str).copy()\n",
    "\n",
    "    # ембедінги + PCA (fit на train у першому фолді, далі тільки transform)\n",
    "    if len(emb_cols) > 0:\n",
    "        Z_tr = df.loc[tr, emb_cols].to_numpy(dtype=\"float32\")\n",
    "        Z_te = df.loc[te, emb_cols].to_numpy(dtype=\"float32\")\n",
    "        if k == 1:\n",
    "            pca.fit(Z_tr)\n",
    "        Z_tr = pca.transform(Z_tr)\n",
    "        Z_te = pca.transform(Z_te)\n",
    "        Ztr_df = pd.DataFrame(Z_tr, index=Xn_tr.index, columns=[f\"pca_emb_{i:02d}\" for i in range(REDUCED_DIM)])\n",
    "        Zte_df = pd.DataFrame(Z_te, index=Xn_te.index, columns=[f\"pca_emb_{i:02d}\" for i in range(REDUCED_DIM)])\n",
    "        Xn_tr = pd.concat([Xn_tr, Ztr_df], axis=1)\n",
    "        Xn_te = pd.concat([Xn_te, Zte_df], axis=1)\n",
    "\n",
    "    # фінальна матриця фіч\n",
    "    X_tr = pd.concat([Xn_tr, Xc_tr], axis=1)\n",
    "    X_te = pd.concat([Xn_te, Xc_te], axis=1)\n",
    "    cat_idx = [X_tr.columns.get_loc(c) for c in Xc_tr.columns]\n",
    "\n",
    "    # пули\n",
    "    train_pool = Pool(X_tr, y_tr, cat_features=cat_idx)\n",
    "    test_pool  = Pool(X_te, y_te, cat_features=cat_idx)\n",
    "\n",
    "    # модель\n",
    "    model = CatBoostClassifier(\n",
    "        loss_function=\"MultiClass\",\n",
    "        iterations=3000, learning_rate=0.05, depth=8,\n",
    "        l2_leaf_reg=8, auto_class_weights=\"Balanced\",\n",
    "        random_state=42, task_type=\"GPU\",\n",
    "        od_type=\"Iter\", od_wait=100, verbose=200\n",
    "    )\n",
    "    model.fit(train_pool, eval_set=test_pool, use_best_model=True)\n",
    "\n",
    "    # прогнози\n",
    "    y_pred = model.predict(test_pool).astype(int).ravel()\n",
    "    y_proba = model.predict_proba(test_pool)  # shape: (N, 3)\n",
    "    macro_f1 = f1_score(y_te, y_pred, average=\"macro\")\n",
    "    bal_acc  = balanced_accuracy_score(y_te, y_pred)\n",
    "\n",
    "    # per-class F1\n",
    "    f1_per_class = f1_score(y_te, y_pred, average=None)  # порядок класів 0,1,2\n",
    "    cm = confusion_matrix(y_te, y_pred, labels=[0,1,2])\n",
    "\n",
    "    print(f\"FOLD {k}  macro-F1={macro_f1:.3f}  balanced-acc={bal_acc:.3f}\")\n",
    "    print(\"Per-class F1:\", {c: round(v,3) for c, v in zip([0,1,2], f1_per_class)})\n",
    "    print(\"Confusion matrix (rows=true, cols=pred):\\n\", cm)\n",
    "\n",
    "    # зберегти метрики фолду\n",
    "    all_fold_metrics.append({\n",
    "        \"fold\": k,\n",
    "        \"macro_f1\": float(macro_f1),\n",
    "        \"balanced_acc\": float(bal_acc),\n",
    "        \"f1_class_0\": float(f1_per_class[0]),\n",
    "        \"f1_class_1\": float(f1_per_class[1]),\n",
    "        \"f1_class_2\": float(f1_per_class[2]),\n",
    "        \"cm_00\": int(cm[0,0]), \"cm_01\": int(cm[0,1]), \"cm_02\": int(cm[0,2]),\n",
    "        \"cm_10\": int(cm[1,0]), \"cm_11\": int(cm[1,1]), \"cm_12\": int(cm[1,2]),\n",
    "        \"cm_20\": int(cm[2,0]), \"cm_21\": int(cm[2,1]), \"cm_22\": int(cm[2,2]),\n",
    "    })\n",
    "\n",
    "    # трекінг найкращої моделі\n",
    "    if macro_f1 > best_macro_f1:\n",
    "        best_macro_f1 = macro_f1\n",
    "        best_model = model\n",
    "        best_fold_id = k\n",
    "\n",
    "    # збережемо тестові прогнози цього фолду з координатами — для карти та аналізу\n",
    "    out_te = df.loc[te, [\"x_merc\",\"y_merc\",\"rgt\",\"track\",\"spot\"]].copy()\n",
    "    out_te[\"y_true\"] = y_te.values\n",
    "    out_te[\"y_pred\"] = y_pred\n",
    "    out_te[\"prob_low\"]  = y_proba[:,0]\n",
    "    out_te[\"prob_mid\"]  = y_proba[:,1]\n",
    "    out_te[\"prob_high\"] = y_proba[:,2]\n",
    "    out_te[\"fold\"] = k\n",
    "    test_preds_concat.append(out_te)\n",
    "\n",
    "# --- підсумки по фолдах ---\n",
    "metrics_df = pd.DataFrame(all_fold_metrics)\n",
    "metrics_df.to_csv(os.path.join(SAVE_DIR, \"cv_metrics.csv\"), index=False)\n",
    "\n",
    "print(\"\\n===== CV SUMMARY =====\")\n",
    "for col in [\"macro_f1\", \"balanced_acc\", \"f1_class_0\", \"f1_class_1\", \"f1_class_2\"]:\n",
    "    mu, sd = metrics_df[col].mean(), metrics_df[col].std()\n",
    "    print(f\"{col}: {mu:.3f} ± {sd:.3f}\")\n",
    "\n",
    "print(f\"\\nBest fold = {best_fold_id}  (macro-F1={best_macro_f1:.3f})\")\n",
    "\n",
    "# збереження найкращої моделі та (за потреби) PCA + маніфест колонок\n",
    "best_model.save_model(os.path.join(SAVE_DIR, \"catboost_fabdem_best.cbm\"))\n",
    "if pca is not None:\n",
    "    joblib.dump(pca, os.path.join(SAVE_DIR, \"pca_embeddings.pkl\"))\n",
    "\n",
    "columns_manifest = {\n",
    "    \"numeric\": list(X_tr.select_dtypes(include=[np.number]).columns),\n",
    "    \"categorical\": list(Xc_tr.columns),\n",
    "    \"target\": \"cls_nmad_fab\",\n",
    "    \"pca_dim\": REDUCED_DIM if pca is not None else 0\n",
    "}\n",
    "json.dump(columns_manifest, open(os.path.join(SAVE_DIR, \"columns_manifest.json\"), \"w\"), ensure_ascii=False, indent=2)\n",
    "\n",
    "# усі тестові прогнози разом (для швидкої перевірки на карті)\n",
    "test_preds_df = pd.concat(test_preds_concat, axis=0).reset_index(drop=True)\n",
    "test_preds_df.to_parquet(os.path.join(SAVE_DIR, \"cv_test_predictions.parquet\"))\n",
    "print(\"\\nSaved:\")\n",
    "print(\" - CV metrics ->\", os.path.join(SAVE_DIR, \"cv_metrics.csv\"))\n",
    "print(\" - Best model ->\", os.path.join(SAVE_DIR, \"catboost_fabdem_best.cbm\"))\n",
    "print(\" - Columns manifest ->\", os.path.join(SAVE_DIR, \"columns_manifest.json\"))\n",
    "print(\" - PCA (optional) ->\", os.path.join(SAVE_DIR, \"pca_embeddings.pkl\"))\n",
    "print(\" - Test preds ->\", os.path.join(SAVE_DIR, \"cv_test_predictions.parquet\"))\n"
   ],
   "id": "f16623977ac094a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== FOLD 1 =====\n",
      "0:\tlearn: 1.0026285\ttest: 1.0027050\tbest: 1.0027050 (0)\ttotal: 81.7ms\tremaining: 4m 5s\n",
      "200:\tlearn: 0.0125199\ttest: 0.0138228\tbest: 0.0138228 (200)\ttotal: 5.82s\tremaining: 1m 20s\n",
      "400:\tlearn: 0.0112413\ttest: 0.0136391\tbest: 0.0136367 (371)\ttotal: 12.1s\tremaining: 1m 18s\n",
      "bestTest = 0.01361867171\n",
      "bestIteration = 486\n",
      "Shrink model to first 487 iterations.\n",
      "FOLD 1  macro-F1=0.993  balanced-acc=0.993\n",
      "Per-class F1: {0: np.float64(0.994), 1: np.float64(0.989), 2: np.float64(0.995)}\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[222388   1661      0]\n",
      " [  1136 226724    557]\n",
      " [     0   1687 233476]]\n",
      "\n",
      "===== FOLD 2 =====\n",
      "0:\tlearn: 1.0027753\ttest: 1.0027642\tbest: 1.0027642 (0)\ttotal: 26.2ms\tremaining: 1m 18s\n",
      "200:\tlearn: 0.0158536\ttest: 0.0162352\tbest: 0.0162352 (200)\ttotal: 5.83s\tremaining: 1m 21s\n",
      "400:\tlearn: 0.0143062\ttest: 0.0159153\tbest: 0.0159153 (400)\ttotal: 12.4s\tremaining: 1m 20s\n",
      "600:\tlearn: 0.0132718\ttest: 0.0158759\tbest: 0.0158735 (583)\ttotal: 19.2s\tremaining: 1m 16s\n",
      "bestTest = 0.01586525908\n",
      "bestIteration = 651\n",
      "Shrink model to first 652 iterations.\n",
      "FOLD 2  macro-F1=0.992  balanced-acc=0.992\n",
      "Per-class F1: {0: np.float64(0.992), 1: np.float64(0.988), 2: np.float64(0.996)}\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[236687   3376      0]\n",
      " [   341 230148   1270]\n",
      " [     0    493 238883]]\n",
      "\n",
      "===== FOLD 3 =====\n",
      "0:\tlearn: 1.0027724\ttest: 1.0026837\tbest: 1.0026837 (0)\ttotal: 31.5ms\tremaining: 1m 34s\n",
      "200:\tlearn: 0.0157980\ttest: 0.0152535\tbest: 0.0152535 (200)\ttotal: 7.12s\tremaining: 1m 39s\n",
      "400:\tlearn: 0.0145797\ttest: 0.0149447\tbest: 0.0149447 (400)\ttotal: 15.2s\tremaining: 1m 38s\n",
      "600:\tlearn: 0.0138664\ttest: 0.0149082\tbest: 0.0149046 (583)\ttotal: 23.6s\tremaining: 1m 34s\n",
      "bestTest = 0.01490019824\n",
      "bestIteration = 670\n",
      "Shrink model to first 671 iterations.\n",
      "FOLD 3  macro-F1=0.992  balanced-acc=0.992\n",
      "Per-class F1: {0: np.float64(0.997), 1: np.float64(0.987), 2: np.float64(0.992)}\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[75310   524     0]\n",
      " [    0 72762   468]\n",
      " [    0   962 87445]]\n",
      "\n",
      "===== FOLD 4 =====\n",
      "0:\tlearn: 1.0026922\ttest: 1.0026959\tbest: 1.0026959 (0)\ttotal: 43.5ms\tremaining: 2m 10s\n",
      "200:\tlearn: 0.0150017\ttest: 0.0154433\tbest: 0.0154433 (200)\ttotal: 7.52s\tremaining: 1m 44s\n",
      "400:\tlearn: 0.0137983\ttest: 0.0152632\tbest: 0.0152603 (376)\ttotal: 15.6s\tremaining: 1m 40s\n",
      "bestTest = 0.01524372864\n",
      "bestIteration = 479\n",
      "Shrink model to first 480 iterations.\n",
      "FOLD 4  macro-F1=0.993  balanced-acc=0.993\n",
      "Per-class F1: {0: np.float64(0.993), 1: np.float64(0.989), 2: np.float64(0.995)}\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[74894   143     0]\n",
      " [  855 81171   175]\n",
      " [    0   552 71119]]\n",
      "\n",
      "===== FOLD 5 =====\n",
      "0:\tlearn: 1.0027006\ttest: 1.0027268\tbest: 1.0027268 (0)\ttotal: 43.3ms\tremaining: 2m 9s\n",
      "200:\tlearn: 0.0127029\ttest: 0.0137676\tbest: 0.0137676 (200)\ttotal: 7.31s\tremaining: 1m 41s\n",
      "400:\tlearn: 0.0116100\ttest: 0.0135807\tbest: 0.0135800 (397)\ttotal: 15.3s\tremaining: 1m 39s\n",
      "600:\tlearn: 0.0108241\ttest: 0.0135285\tbest: 0.0135281 (594)\ttotal: 23.7s\tremaining: 1m 34s\n",
      "bestTest = 0.01351726699\n",
      "bestIteration = 665\n",
      "Shrink model to first 666 iterations.\n",
      "FOLD 5  macro-F1=0.993  balanced-acc=0.993\n",
      "Per-class F1: {0: np.float64(0.996), 1: np.float64(0.99), 2: np.float64(0.994)}\n",
      "Confusion matrix (rows=true, cols=pred):\n",
      " [[51513   130     0]\n",
      " [  251 50425   386]\n",
      " [    0   294 53274]]\n",
      "\n",
      "===== CV SUMMARY =====\n",
      "macro_f1: 0.992 ± 0.001\n",
      "balanced_acc: 0.993 ± 0.000\n",
      "f1_class_0: 0.994 ± 0.002\n",
      "f1_class_1: 0.989 ± 0.001\n",
      "f1_class_2: 0.994 ± 0.002\n",
      "\n",
      "Best fold = 5  (macro-F1=0.993)\n",
      "\n",
      "Saved:\n",
      " - CV metrics -> artifacts_fabdem_cv\\cv_metrics.csv\n",
      " - Best model -> artifacts_fabdem_cv\\catboost_fabdem_best.cbm\n",
      " - Columns manifest -> artifacts_fabdem_cv\\columns_manifest.json\n",
      " - PCA (optional) -> artifacts_fabdem_cv\\pca_embeddings.pkl\n",
      " - Test preds -> artifacts_fabdem_cv\\cv_test_predictions.parquet\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
